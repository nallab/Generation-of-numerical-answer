{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# クエリを文にするか\n",
    "# 単語の羅列からモデルを作る\n",
    "search_query = '琉球大学 4年間 学費 いくら'\n",
    "#search_sentence = \"100円のノートを4冊買う時の値段\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "琉球大学\n",
      "の\n",
      "4\n",
      "年間\n",
      "の\n",
      "学費\n",
      "は\n",
      "いくら\n",
      "か\n"
     ]
    }
   ],
   "source": [
    "import CaboCha\n",
    "cabocha = CaboCha.Parser()\n",
    "search_sentence = '琉球大学の4年間の学費はいくらか'\n",
    "tree =  cabocha.parse(search_sentence)\n",
    "size = tree.token_size()\n",
    "chunks = []\n",
    "text = \"\"\n",
    "toChunkId = -1\n",
    "dependency_relation = {}\n",
    "for i in range(size):\n",
    "    token = tree.token(i) \n",
    "    print(token.surface)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'c': '琉球大学の', 'to': 1}, {'c': '4年間の', 'to': 2}, {'c': '学費は', 'to': 3}, {'c': 'いくらか', 'to': -1}]\n",
      "{2: '年間'}\n"
     ]
    }
   ],
   "source": [
    "import CaboCha\n",
    "cabocha = CaboCha.Parser()\n",
    "search_sentence = '琉球大学の4年間の学費はいくらか'\n",
    "tree =  cabocha.parse(search_sentence)\n",
    "size = tree.token_size()\n",
    "chunks = []\n",
    "text = \"\"\n",
    "toChunkId = -1\n",
    "dependency_relation = {}\n",
    "for i in range(size):\n",
    "    token = tree.token(i) # cabocha にかけた文章を形態素ごとに取得\n",
    "    text = token.surface if token.chunk else (text + token.surface) #  上記の出力結果のchunk(文節)ごとにtextが更新されていく\n",
    "    toChunkId = token.chunk.link if token.chunk else toChunkId\n",
    "    # 文末かchunk内の最後の要素のタイミングで出力\n",
    "    if \"助数詞\" in token.feature:\n",
    "        dependency_relation[toChunkId] = token.surface  # 助数詞を格納\n",
    "    if i == size - 1 or tree.token(i+1).chunk:\n",
    "        chunks.append({'c': text, 'to': toChunkId})\n",
    "print(chunks)\n",
    "print(dependency_relation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import CaboCha\n",
    "\n",
    "def cabocha_searh(search_sentence):\n",
    "    cabocha = CaboCha.Parser()\n",
    "    tree =  cabocha.parse(search_sentence)\n",
    "    size = tree.token_size()\n",
    "    chunks = []\n",
    "    text = \"\"\n",
    "    toChunkId = -1\n",
    "    dependency_relation = {}\n",
    "    for i in range(size):\n",
    "        token = tree.token(i) # cabocha にかけた文章を形態素ごとに取得\n",
    "        text = token.surface if token.chunk else (text + token.surface) #  上記の出力結果のchunk(文節)ごとにtextが更新されていく\n",
    "        toChunkId = token.chunk.link if token.chunk else toChunkId\n",
    "        # 文末かchunk内の最後の要素のタイミングで出力\n",
    "        if \"助数詞\" in token.feature:\n",
    "            dependency_relation[toChunkId] = token.surface  # 助数詞を格納\n",
    "        if i == size - 1 or tree.token(i+1).chunk:\n",
    "            chunks.append({'c': text, 'to': toChunkId})\n",
    "    return chunks,dependency_relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_count_words(search_sentence):\n",
    "    cabocha = CaboCha.Parser()\n",
    "    tree =  cabocha.parse(search_sentence)\n",
    "    size = tree.token_size()\n",
    "    toChunkId = -1\n",
    "    count_words = {}\n",
    "    for i in range(size):\n",
    "        token = tree.token(i) # cabocha にかけた文章を形態素ごとに取得\n",
    "        toChunkId = token.chunk.link if token.chunk else toChunkId\n",
    "        # 文末かchunk内の最後の要素のタイミングで出力\n",
    "        if \"助数詞\" in token.feature:\n",
    "            count_words[toChunkId] = token.surface  # 助数詞を格納\n",
    "    return count_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2: '年間'}\n"
     ]
    }
   ],
   "source": [
    "count_words = search_count_words(search_sentence)\n",
    "print(count_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_dependency_relation(count_words):\n",
    "    cabocha = CaboCha.Parser()\n",
    "    tree =  cabocha.parse(search_sentence)\n",
    "    size = tree.token_size()\n",
    "    ChunkId = 0\n",
    "    dependency_relation = {}\n",
    "    for i in range(size):\n",
    "        if i == size - 1 or tree.token(i+1).chunk:\n",
    "            ChunkId = ChunkId + 1\n",
    "        token = tree.token(i) # cabocha にかけた文章を形態素ごとに取得\n",
    "        # 文末かchunk内の最後の要素のタイミングで出力\n",
    "        print(ChunkId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "search_dependency_relation(count_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
